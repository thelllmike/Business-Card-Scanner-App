{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41169235-2972-4164-8049-2baf6319abd2",
   "metadata": {},
   "source": [
    "# Step 1: Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87b9e63-c459-4275-92b5-97cea83c2303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.66.4)\n",
      "Collecting doccano-client\n",
      "  Downloading doccano_client-1.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\micheal\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\micheal\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from doccano-client)\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-1.10.17-cp312-cp312-win_amd64.whl.metadata (153 kB)\n",
      "     ---------------------------------------- 0.0/153.0 kB ? eta -:--:--\n",
      "     --------- --------------------------- 41.0/153.0 kB 991.0 kB/s eta 0:00:01\n",
      "     --------- --------------------------- 41.0/153.0 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.4/153.0 kB 409.6 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 112.6/153.0 kB 595.3 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 133.1/153.0 kB 605.3 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 143.4/153.0 kB 500.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 153.0/153.0 kB 508.1 kB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<0.10.0,>=0.9.1 (from doccano-client)\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->doccano-client)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->doccano-client)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\micheal\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->doccano-client)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\micheal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading doccano_client-1.2.8-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.0 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 41.0/109.0 kB 991.0 kB/s eta 0:00:01\n",
      "   ----------------------------- --------- 81.9/109.0 kB 919.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 109.0/109.0 kB 906.3 kB/s eta 0:00:00\n",
      "Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Downloading pydantic-1.10.17-cp312-cp312-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.9 MB 991.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.1/1.9 MB 1.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/1.9 MB 952.6 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 958.4 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 321.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 321.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 321.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 321.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 285.3 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/1.9 MB 288.0 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.3/1.9 MB 290.2 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.4/1.9 MB 305.4 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.4/1.9 MB 319.2 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.5/1.9 MB 356.8 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 383.7 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.6/1.9 MB 408.7 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.6/1.9 MB 437.0 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.7/1.9 MB 460.9 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 0.7/1.9 MB 487.9 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 520.4 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.9/1.9 MB 544.1 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.9/1.9 MB 566.4 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/1.9 MB 593.6 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/1.9 MB 595.3 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 614.4 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 632.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.2/1.9 MB 660.8 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/1.9 MB 677.2 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/1.9 MB 697.9 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 717.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 751.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 763.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 780.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 797.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 794.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 782.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 678.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 716.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 715.2 kB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.3 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 10.2/54.3 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 30.7/54.3 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 54.3/54.3 kB 468.9 kB/s eta 0:00:00\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.2/49.2 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: pytesseract, pydantic, mypy-extensions, marshmallow, typing-inspect, requests-toolbelt, dataclasses-json, doccano-client\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.4\n",
      "    Uninstalling pydantic-2.7.4:\n",
      "      Successfully uninstalled pydantic-2.7.4\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 1.0.0\n",
      "    Uninstalling requests-toolbelt-1.0.0:\n",
      "      Successfully uninstalled requests-toolbelt-1.0.0\n",
      "Successfully installed dataclasses-json-0.5.14 doccano-client-1.2.8 marshmallow-3.21.3 mypy-extensions-1.0.0 pydantic-1.10.17 pytesseract-0.3.10 requests-toolbelt-0.9.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy tqdm doccano-client pytesseract pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd470dad-b303-4599-a7ce-2dbcf574480f",
   "metadata": {},
   "source": [
    "# Step 2: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89e63ee-eff3-4244-b3c8-90d5f2eeb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60271d8a-944d-484c-80cb-7c09a85b11b3",
   "metadata": {},
   "source": [
    "# Set the path to the Tesseract executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2ff995-d515-4685-b1d3-21f24e6b4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Windows\n",
    "# pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'  # macOS/Linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce030ba8-b281-4eb0-9b35-af5c6e1f829c",
   "metadata": {},
   "source": [
    "# Step 3: Extract text from business card images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eb75b7-564f-43bb-b503-d5c3dcda7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "image_folder = 'images'\n",
    "extracted_texts = []\n",
    "\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if image_file.endswith(('png', 'jpg', 'jpeg')):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        text = extract_text_from_image(image_path)\n",
    "        extracted_texts.append((image_file, text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cacfdf-19c9-435b-8728-b55aa8d49719",
   "metadata": {},
   "source": [
    "# Save extracted texts to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040576a9-40a0-40d6-a864-97805916d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracted_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    for image_file, text in extracted_texts:\n",
    "        f.write(f'File: {image_file}\\n{text}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae687d98-2663-483c-9537-7b2631dfc8eb",
   "metadata": {},
   "source": [
    "# Step 4: Annotate the extracted text using Doccano\n",
    "# Follow the steps in the Doccano section above to create a project, import the data, and annotate the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155703b-9f29-4a60-b208-d5288eff52af",
   "metadata": {},
   "source": [
    "# Step 5: Convert Doccano annotations to spaCy format\n",
    "# Load the doccano JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0598868-83ad-46f3-825e-7d5deefef245",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/doccano_export.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath/to/doccano_export.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/doccano_export.jsonl'"
     ]
    }
   ],
   "source": [
    "with open('path/to/doccano_export.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dcf20-80f6-40a9-a480-3ea7c3d4a7a2",
   "metadata": {},
   "source": [
    "# Convert to spaCy training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137a8fb-b1a5-41ef-a0ae-7d731a2b7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "for entry in data:\n",
    "    text = entry['text']\n",
    "    entities = []\n",
    "    for label in entry['labels']:\n",
    "        entities.append((label[0], label[1], label[2]))\n",
    "    TRAIN_DATA.append((text, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef909e-5331-4975-966e-8302a801fbc0",
   "metadata": {},
   "source": [
    "# Save TRAIN_DATA to a file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb3e27-2979-4067-ab45-89990326ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kenya_business_cards_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(TRAIN_DATA, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bceda5-3226-40de-aed4-0ad8e39326c0",
   "metadata": {},
   "source": [
    "# Step 6: Train the custom NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5957023-57c9-4885-8872-9959a760a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_ner(training_data, output_dir):\n",
    "    # Create a blank Language class\n",
    "    nlp = spacy.blank(\"en\")\n",
    "\n",
    "    # Create the built-in pipeline components and add them to the pipeline\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "    # Add labels to the NER component\n",
    "    for _, annotations in training_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # Start training\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(20):  # Increase the number of iterations as needed\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(training_data):\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "            nlp.update([example], drop=0.5, losses=losses)\n",
    "        print(f\"Iteration {i+1}, Losses: {losses}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    nlp.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a923a-5455-40a4-9268-30d8294c92b4",
   "metadata": {},
   "source": [
    "# Load training data from the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979de2c3-88aa-4191-83f8-3adb33c4d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kenya_business_cards_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    TRAIN_DATA = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20dadd-baee-47d6-9572-dd395da09a74",
   "metadata": {},
   "source": [
    "# Train and save the custom NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd33325-e84f-4fcb-ad76-ffaeccae6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_ner(TRAIN_DATA, \"./custom_ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521c879-b916-410d-ae83-1e767ec5bdcd",
   "metadata": {},
   "source": [
    "# Step 7: Load the trained model and use it for entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a0e0c-461a-4064-ad13-21793b387051",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"./custom_ner_model\")\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.label_: ent.text for ent in doc.ents}\n",
    "\n",
    "    # Validate and clean phone numbers\n",
    "    phone_regex = re.compile(r'(\\+254\\s?\\d{3}\\s?\\d{6})')\n",
    "    phone_matches = phone_regex.findall(text)\n",
    "    if phone_matches:\n",
    "        entities[\"PHONE\"] = phone_matches\n",
    "\n",
    "    # Validate and clean email addresses\n",
    "    email_regex = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b')\n",
    "    email_matches = email_regex.findall(text)\n",
    "    if email_matches:\n",
    "        entities[\"EMAIL\"] = email_matches\n",
    "\n",
    "    # Validate and clean website URLs\n",
    "    website_regex = re.compile(r'\\b(?:http[s]?://)?(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,7}\\b')\n",
    "    website_matches = website_regex.findall(text)\n",
    "    if website_matches:\n",
    "        entities[\"WEBSITE\"] = website_matches\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa64510-17dd-46a4-9c28-3052b3007267",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71df0d3-9eed-4ace-a7a3-be8a506afba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Alice Johnson, CTO at Tech Solutions, phone: +254 711 123456, email: alice.johnson@techsolutions.com, website: www.techsolutions.co.ke, address: 789 Maple Ave, Nairobi, Kenya\"\n",
    "entities = extract_entities(text)\n",
    "print(entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
